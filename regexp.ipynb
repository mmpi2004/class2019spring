{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "외부라이브러리인 nltk를 불러온다.  \n",
    "파이썬 내장 라이브러리인 re를 불러온다. (re 라이브러리는 정규표현(regular expression)을 사용할 때 용이하다.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Basic Regular Expression Meta-Characters, Including Wildcards, Ranges and Closures\\n.\\t        Wildcard, matches any character\\n^abc\\t    Matches some pattern abc at the start of a string\\nabc$\\t    Matches some pattern abc at the end of a string\\n[abc]\\t    Matches one of a set of characters\\n[^abc]      Matches anything but a set of characters\\n[A-Z0-9]\\tMatches one of a range of characters\\ned|ing|s\\tMatches one of the specified strings (disjunction)\\n*\\t        Zero or more of previous item, e.g. a*, [a-z]* (also known as Kleene Closure)\\n+\\t        One or more of previous item, e.g. a+, [a-z]+\\n?\\t        Zero or one of the previous item (i.e. optional), e.g. a?, [a-z]?\\n{n}\\t        Exactly n repeats where n is a non-negative integer\\n{n,}\\t    At least n repeats\\n{,n}\\t    No more than n repeats\\n{m,n}\\t    At least m and no more than n repeats\\na(b|c)+\\t    Parentheses that indicate the scope of the operators'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\" Basic Regular Expression Meta-Characters, Including Wildcards, Ranges and Closures\n",
    ".\t        Wildcard, matches any character\n",
    "^abc\t    Matches some pattern abc at the start of a string\n",
    "abc$\t    Matches some pattern abc at the end of a string\n",
    "[abc]\t    Matches one of a set of characters\n",
    "[^abc]      Matches anything but a set of characters\n",
    "[A-Z0-9]\tMatches one of a range of characters\n",
    "ed|ing|s\tMatches one of the specified strings (disjunction)\n",
    "*\t        Zero or more of previous item, e.g. a*, [a-z]* (also known as Kleene Closure)\n",
    "+\t        One or more of previous item, e.g. a+, [a-z]+\n",
    "?\t        Zero or one of the previous item (i.e. optional), e.g. a?, [a-z]?\n",
    "{n}\t        Exactly n repeats where n is a non-negative integer\n",
    "{n,}\t    At least n repeats\n",
    "{,n}\t    No more than n repeats\n",
    "{m,n}\t    At least m and no more than n repeats\n",
    "a(b|c)+\t    Parentheses that indicate the scope of the operators\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "dic = nltk.corpus.words.words('en')\n",
    "print(type(dic)) #시험문제 예시"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk.corpus.words에서 영어(en)단어들을 리스트로 가져와 변수 dic에 할당한다.  \n",
    "dic의 자료형은 리스트다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'aa', 'aal', 'aalii', 'aam', 'aardvark', 'aardwolf', 'aba', 'abac', 'abaca']\n"
     ]
    }
   ],
   "source": [
    "wordlist = [w for w in nltk.corpus.words.words('en') if w.islower()] # list comprehension\n",
    "print(wordlist[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk.corpus.words의 영단어들의 리스트에서 영단어를 for문을 한번 돌때마다 변수 w에 할당하여 만약 그 단어(w)가 소문자(islower)이면 그 단어를 리스트의 원소로 둔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_sre.SRE_Match object; span=(0, 3), match='abc'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# regular expression은 string에 대해서만 적용가능.\n",
    "re.search('abc', 'abcde')\n",
    "# 인수의 개수는? 2개\n",
    "# 첫번째 인수는 찾고자하는 문자열, 두번째는 대상\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'abcde'에서 'abc'라는 문자열을 탐색(search)한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abaissed', 'abandoned', 'abased', 'abashed', 'abatised', 'abed', 'aborted', 'abridged', 'abscessed', 'absconded']\n"
     ]
    }
   ],
   "source": [
    "result = [w for w in wordlist if re.search('ed$', w)]\n",
    "print(result[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "반복문을 한번 돌 때마다 wordlist에서 한 단어씩 가져와 변수 w에 할당하고, 만약 그 단어가 'ed'로 끝난다면 그 단어를 리스트의 원소로 둔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['abjectly', 'adjuster', 'dejected', 'dejectly', 'injector', 'majestic', 'objectee', 'objector', 'rejecter', 'rejector']\n"
     ]
    }
   ],
   "source": [
    "result = [w for w in wordlist if re.search('^..j..t..$', w)]\n",
    "print(result[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "반복문을 한번 돌 때마다 wordlist에서 한 단어씩 가져와 변수 w에 할당하고, 만약 그 단어가 아무 문자 2개로 시작하고, 그다음은 j, 그 다음은 아무문자 2개, 그 다음은 t, 그 다음은 아무 문자 2개로 끝난다면 그 단어를 리스트의 원소로 둔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gold', 'golf', 'hold', 'hole']\n"
     ]
    }
   ],
   "source": [
    "result = [w for w in wordlist if re.search('^[ghi][mno][jlk][def]$', w)]\n",
    "print(result[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "반복문을 한번 돌 때마다 wordlist에서 한 단어씩 가져와 변수 w에 할당하고, 만약 그 단어가 ghi중 한 문자로 시작하고, 그다음은 mno중 한 문자이고, 그다음은 jlk중 한 문자이고, 그다음은 def중 한 문자로 끝나는 단어(총 4문자)라면 그 단어를 리스트의 원소로 둔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'aa', 'ah', 'aha', 'h', 'ha', 'hah']\n"
     ]
    }
   ],
   "source": [
    "result = [w for w in wordlist if re.search('^[ah]+$', w)]\n",
    "print(result[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "반복문을 한번 돌 때마다 wordlist에서 한 단어씩 가져와 변수 w에 할당하고, 만약 그 단어가 ah중의 문자가 1회 이상 반복하여 이루어져있다면 그 단어를 리스트의 원소로 둔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wsj = sorted(set(nltk.corpus.treebank.words()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk.corpus.treebank의 데이터에서 단어들을 가져와 그것을 set()집합 자료형으로 만든다. 이때 set 자료형은 원소들간의 중복을 허용하지않는다. 따라서 중복되지않는 원소들의 집합으로 이루어져있는데 그것을 sorted()하면 원소들을 오름차순으로 정렬한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0.0085', '0.05', '0.1', '0.16', '0.2', '0.25', '0.28', '0.3', '0.4', '0.5']\n"
     ]
    }
   ],
   "source": [
    "wordlist = [w for w in wsj if re.search('^[0-9]+\\.[0-9]+$', w)]\n",
    "print(wordlist[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wsj의 단어들을 한 iteration마다 단어 한개씩 가져와 변수 w에 할당하고, 만약 그 단어가 0에서 9까지의 하나 이상의 정수들로 시작하고 .(온점)하나가 붙고 그다음에 0에서 9까지의 하나 이상의 정수들로 끝난다면, 그 단어를 리스트의 원소로 둔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C$', 'US$']\n"
     ]
    }
   ],
   "source": [
    "wordlist = [w for w in wsj if re.search('^[A-Z]+\\$$', w)]\n",
    "print(wordlist[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wsj의 단어들을 한 iteration마다 단어 한개씩 가져와 변수 w에 할당하고, 만약 그 단어가 A에서 Z까지의 하나 이상의 대문자로 시작하여 $(달러기호)로 끝난다면, 그 단어를 리스트이 원소로 둔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1614', '1637', '1787', '1901', '1903', '1917', '1925', '1929', '1933', '1934']\n"
     ]
    }
   ],
   "source": [
    "wordlist = [w for w in wsj if re.search('^[0-9]{4}$', w)]\n",
    "print(wordlist[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wsj의 단어들을 한 iteration마다 단어 한개씩 가져와 변수 w에 할당하고, 만약 그 단어가 0에서 9까지의 정수가 4번 반복된다면 그 단어를 리스트의 원소로 둔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['10-day', '10-lap', '10-year', '100-share', '12-point', '12-year', '14-hour', '15-day', '150-point', '190-point']\n"
     ]
    }
   ],
   "source": [
    "wordlist = [w for w in wsj if re.search('^[0-9]+-[a-z]{3,5}$', w)]\n",
    "print(wordlist[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wsj의 단어들을 한 iteration마다 단어 한개씩 가져와 변수 w에 할당하고, 만약 그 단어가 0~9의 1회이상 반복되는 정수들로 시작하고 -(대쉬)기호가 그다음에 이어지고 a~z의 소문자가 3회이상 5회이하 반복하여 끝난다면 그 단어를 리스트의 원소로 둔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['black-and-white', 'bread-and-butter', 'father-in-law', 'machine-gun-toting', 'savings-and-loan']\n"
     ]
    }
   ],
   "source": [
    "wordlist = [w for w in wsj if re.search('^[a-z]{5,}-[a-z]{2,3}-[a-z]{,6}$', w)]\n",
    "print(wordlist[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wsj의 단어들을 한 iteration마다 단어 한개씩 가져와 변수 w에 할당하고, 만약 그 단어가 a~z 소문자가 5회 이상 반복하여 시작하고 그다음엔 -(대쉬)기호가 이어지고 그다음엔 a~z 소문자가 6회 이하 반복되어 끝난다면, 그 단어를 리스트의 원소로 둔다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['62%-owned', 'Absorbed', 'According', 'Adopting', 'Advanced', 'Advancing', 'Alfred', 'Allied', 'Annualized', 'Anything']\n"
     ]
    }
   ],
   "source": [
    "wordlist = [w for w in wsj if re.search('(ed|ing)$', w)]\n",
    "print(wordlist[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "wsj의 단어들을 한 iteration마다 단어 한개씩 가져와 변수 w에 할당하고, 만약 그 단어가 ed 또는 ing으로 끝난다면 그 단어를 리스트의 원소로 둔다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "여기까지 내용정리, 밑의 코드 어떻게 된건지 설명."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['u', 'e', 'a', 'i', 'a', 'i', 'i', 'i', 'e', 'i', 'a', 'i', 'o', 'i', 'o', 'u']\n"
     ]
    }
   ],
   "source": [
    "word = 'supercalifragilisticexpialidocious'\n",
    "result = re.findall(r'[aeiou]', word)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'supercalifragilisticexpialidocious' 라는 문자열을 변수 word에 할당.  \n",
    "문자열 word에서 aeiou 중 매칭되는 한문자가 있다면, word에서 매칭되는 문자를 모두 찾아서 하나의 리스트로 만든다. 따라서 'supercalifragilisticexpialidocious' 문자열의 앞에서부터 차례로 a,e,i,o,u 중에 맞는 문자들을 찾아내 리스트에 넣는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rc', 'fr', 'st', 'xp', 'ci']\n"
     ]
    }
   ],
   "source": [
    "result = re.findall('[aeiou](..)[aeiou]', word)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문자열 word에서 aeiou 중의 한문자 뒤에 아무문자 2개가 이어지고 그다음에 aeiou중 한문자로 이어지는 패턴이 발견되면 정규표현의 괄호에 묶에있는 (..) 아무 문자 두개만을 추출하여 리스트의 원소로 둔다. 정규표현에서 ()괄호로 묶는 것은 연산자(ex. $)의 적용범위를 나타내는 기능도 있으나, 또다른 기능은 괄호에 묶인것만을 결과로 추출하는 기능이다. 이 예시처럼 re.findall()에서 정규표현에 괄호로 묶는 것(일명, grouping)이 있다면, 전체 정규표현에 매칭되는 모든 것을 찾고, 매칭된 문자열중에 괄호에 묶인 것들만 결과로서 추출한다.  \n",
    "cf. re.match() re.search에서 괄호(grouping)를 사용할 경우 .group(1)이라는 메서드를 사용하면 위처럼 괄호안의 내용만 따로 추출한다. 만약 group()메서드를 뒤에 붙이지않는다면 전체 정규표현에 매칭되는 것을 그대로 준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['supercalifragilisticexpialidocious']\n"
     ]
    }
   ],
   "source": [
    "result = re.findall('[^aeiou].+[^aeiou]', word)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문자열 word에서 {'자음한개' 다음에 '1회이상의 아무문자' 다음에 '자음'}으로 이루어진 부분을 모두 찾는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sup', 'rcal', 'frag', 'lis', 'tic', 'xpial', 'doc']\n"
     ]
    }
   ],
   "source": [
    "result = re.findall('[^aeiou].+?[^aeiou]', word)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "문자열 word에서 {'자음 한개' 다음에 '아무문자가 1회 이상 반복'하되 최소매칭되고, 그 다음에 자음'}으로 이루어진 부분을 모두 찾는다. + 또는 * 과 같은 탐욕적 연산자 뒤에 붙는 ?은 매칭할 수 있는 범위를 최소로 한다는 뜻이다. .+?[^aeiou] 가 의미하는 바는 아무문자가 1회이상 반복되지만 자음[^aeiou]이 나오기 전까지만 .+을 매칭시킨다는 뜻이다. 즉, 가능한 최소로 매칭시킨다는 뜻."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FreqDist({'io': 549, 'ea': 476, 'ie': 331, 'ou': 329, 'ai': 261, 'ia': 253, 'ee': 217, 'oo': 174, 'ua': 109, 'au': 106, ...})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wsj = sorted(set(nltk.corpus.treebank.words()))\n",
    "fdist = nltk.FreqDist(vs for word in wsj for vs in re.findall(r'[aeiou]{2,}', word))\n",
    "fdist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk.corpus.treebank데이터로 부터 단어들의 리스트를 가져와 set()을 하면 원소가 중복되지않는 집합으로 변환되며, 거기에 sorted를 하면 오름차순으로 단어들이 정렬된다. 쉽게 생각하자면, 서로 중복되지않으며, 사전식으로 정렬된 단어들의 집합이라고 할 수 있다.  \n",
    "\n",
    "fdist = nltk.FreqDist(vs for word in wsj for vs in re.findall(r'[aeiou]{2,}', word))  \n",
    "\n",
    "FreqDist의 인자는 리스트다. vs for word in wsj for vs in re.findall(r'[aeiou]{2,}', word 는 list comprehension으로 표현된 것이다.  \n",
    "wsj 리스트의 단어들을 한 iteration마다 한 단어씩 변수 word에 할당하고, 각 word에 대해서 모음이 2회이상 반복되는 부분을 모두 찾아서 그 부분들을 어떤 리스트에 축적시킨다. 이렇게 wsj의 모든 단어들에 대해서 찾은 2회이상 반복되는 모음부분들로 이루어진 리스트를 FreqDist함수에 넣어서 그 리스트 원소들의 빈도분포를 반환받는다.\n",
    "\n",
    "빈도분포 결과를 보자면, io라는 모음부분은 wsj의 단어들에서 549회 등장했다.\n",
    "\n",
    "\n",
    "Q. 만약 사전을 FreqDist()에 넣어서 most_common(10)하면 상위 10개의 단어들의 빈도수는? A. 모두 1.(사전은 단어들이 중복되지않기 때문)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unvrsl Dclrtn of Hmn Rghts Prmble Whrs rcgntn of the inhrnt dgnty and\n",
      "of the eql and inlnble rghts of all mmbrs of the hmn fmly is the fndtn\n",
      "of frdm , jstce and pce in the wrld , Whrs dsrgrd and cntmpt fr hmn\n",
      "rghts hve rsltd in brbrs acts whch hve outrgd the cnscnce of mnknd ,\n",
      "and the advnt of a wrld in whch hmn bngs shll enjy frdm of spch and\n"
     ]
    }
   ],
   "source": [
    "regexp = r'^[AEIOUaeiou]+|[AEIOUaeiou]+$|[^AEIOUaeiou]'\n",
    "def compress(word):\n",
    "    pieces = re.findall(regexp, word)\n",
    "    return ''.join(pieces)\n",
    "\n",
    "english_udhr = nltk.corpus.udhr.words('English-Latin1')\n",
    "print(nltk.tokenwrap(compress(w) for w in english_udhr[:75]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "r'^[AEIOUaeiou]+|[AEIOUaeiou]+$|[^AEIOUaeiou]'라는 정규표현을 변수 regexp에 할당한다.  \n",
    "\n",
    "compress(word)함수는 인자로 들어온 word에 대해서 regexp라는 정규표현에 매칭되는 모든것을 찾아(findall) 그 리스트를 변수 pieces에 할당한다. 그리고 pieces에 할당된 리스트의 원소들을 ''빈 문자열로 묶어, 즉, 모든 원소들을 빈틈없이 붙여서(join) 하나의 문자열로 만들어 반환(return)한다. (compress의 결과는 단어에서 처음과 끝을 제외한 중간에 있는 모음들을 제거한 형태다.)\n",
    "\n",
    "nltk.corpus.udhr 데이터로부터 'English-Latin1' 텍스트의 단어들을 리스트 형태로 가져와 english_udhr 변수에 할당한다.  \n",
    "english_udhr의 단어들 중 0번째부터 74번째까지의 단어들을 가져와 1 iteration마다 한단어씩 변수 w에 할당하고, 그 단어 w를 compress 함수에 적용시킨다. 즉, 단어 w로부터 regexp에 매칭되는 부분들을 모두 찾아 하나의 문자열로 붙인다. 75개의 단어들에 대해서 compress한 뒤 그 문자열들의 리스트를 tokenwrap하면 리스트의 문자열들(토큰들)을 whitespace(' ')로 묶어서(wrap) 하나의 문자열을 출력한다. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(nltk.tokenwrap(compress(w) for w in english_udhr[:75]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "따라서 tokenwrap의 반환값은 문자열이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    a   e   i   o   u \n",
      "k 418 148  94 420 173 \n",
      "p  83  31 105  34  51 \n",
      "r 187  63  84  89  79 \n",
      "s   0   0 100   2   1 \n",
      "t  47   8   0 148  37 \n",
      "v  93  27 105  48  49 \n"
     ]
    }
   ],
   "source": [
    "rotokas_words = nltk.corpus.toolbox.words('rotokas.dic')\n",
    "cvs = [cv for w in rotokas_words for cv in re.findall(r'[ptksvr][aeiou]', w)]\n",
    "cfd = nltk.ConditionalFreqDist(cvs) # CFD works pairwise only\n",
    "cfd.tabulate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk.corpus.toolbox 데이터로 부터 'rotokas.dic'텍스트의 단어들을 리스트 형태로 가져와 변수 rotokas_words에 지정한다.  \n",
    "rotokas_words의 단어들을 한 iteration마다 한단어씩 변수 w에 할당하고, 그 단어 w에서 {ptksvr중 한문자 다음에 모음}에 매칭되는 모든 부분을 찾은 다음, 그 부분을 cvs라는 리스트에 축적시킨다. 쉽게 설명하자면, rotokas_words에 있는 모든 단어들에 대해서 {ptksvr중 한문자 + 모음} 부분을 모두 찾아내어 cvs 리스트에 저장하라는 말이다.  \n",
    "그렇게 매칭된 부분들을 모아둔 cvs 리스트에 대해서 ConditionalFreqDist를 하면 cvs리스트의 원소인 문자열(두문자 ex.'ka')을 (한문자 'k', 한문자 'a')로 쪼개어 pair를 만든다. (한문자, 한문자)는 (condition, event)에 대응된다. 따라서 condition(p,t,k,s,v,r)과 event(a,e,i,o,u)의 모든 조합에 해당되는 빈도수들을 구한다.  \n",
    "A conditional frequency distribution is a collection of frequency distributions, each one for a different \"condition\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['k', 'r', 'v', 's', 't', 'p']\n"
     ]
    }
   ],
   "source": [
    "print(cfd.conditions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kaapo',\n",
       " 'kaapopato',\n",
       " 'kaipori',\n",
       " 'kaiporipie',\n",
       " 'kaiporivira',\n",
       " 'kapo',\n",
       " 'kapoa',\n",
       " 'kapokao',\n",
       " 'kapokapo',\n",
       " 'kapokapo',\n",
       " 'kapokapoa',\n",
       " 'kapokapoa',\n",
       " 'kapokapora',\n",
       " 'kapokapora',\n",
       " 'kapokaporo',\n",
       " 'kapokaporo',\n",
       " 'kapokari',\n",
       " 'kapokarito',\n",
       " 'kapokoa',\n",
       " 'kapoo',\n",
       " 'kapooto',\n",
       " 'kapoovira',\n",
       " 'kapopaa',\n",
       " 'kaporo',\n",
       " 'kaporo',\n",
       " 'kaporopa',\n",
       " 'kaporoto',\n",
       " 'kapoto',\n",
       " 'karokaropo',\n",
       " 'karopo',\n",
       " 'kepo',\n",
       " 'kepoi',\n",
       " 'keposi',\n",
       " 'kepoto']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_word_pairs = [(cv, w) for w in rotokas_words for cv in re.findall(r'[ptksvr][aeiou]', w)]\n",
    "cv_index = nltk.Index(cv_word_pairs)\n",
    "cv_index['po']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "rotokas_words의 단어들을 한 iteration마다 한단어씩 변수 w에 할당하고, 그 단어 w에서 {ptksvr중 한문자 다음에 모음}에 매칭되는 모든 부분을 찾은 다음, (단어, 그 단어의 매칭된 부분)의 pair를 원소로 하는 리스트를 변수 cv_word_pairs에 할당한다. nltk.Index(cv_word_pairs)를 하면, pair의 뒷부분, 즉, '그 단어의 매칭된 부분'을 인덱스로 삼아 '그 단어의 매칭된 부분'을 갖고 있는 모든 '단어'들에 접근할 수 있다. 예를 들어, cv_index['po'] 하면, 'po'라는 부분을 갖고 있는 모든 단어들의 리스트를 반환해준다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nltk.util.Index'>\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(cv_index))\n",
    "print(type(cv_index['po']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
